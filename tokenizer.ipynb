{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCH6ijxOt+UOnC7YlhPmI6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/au1206/build_llm_from_scratch/blob/main/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUjTCL3R042E"
      },
      "outputs": [],
      "source": [
        "# prompt: explain the regex text = re.sub(r'([,.?_!\"()\\']|--|\\s)', r'\\1', text)\n",
        "\n",
        "The provided regex `text = re.sub(r'([,.?_!\"()\\']|--|\\s)', r'\\1', text)` performs the following operations:\n",
        "\n",
        "1. **Character Class**:\n",
        "   - `([,.?_!\"()\\'])`: This character class matches any of the special characters: comma (,), period (.), question mark (?), underscore (_), exclamation mark (!), double quotes (\"), single quotes ('), opening and closing parentheses (), and hyphen (--).\n",
        "\n",
        "2. **Grouping**:\n",
        "   - The parentheses around the character class create a capturing group, allowing us to refer to the matched character later using `\\1`.\n",
        "\n",
        "3. **Replacement**:\n",
        "   - `r'\\1'`: This replacement string simply reinserts the captured character (`\\1`) at the same position where it was matched.\n",
        "\n",
        "4. **Overall Effect**:\n",
        "   - The regex effectively removes any whitespace or special characters from the text and replaces them with themselves. This can be useful for pre-processing text data, such as removing punctuation or formatting characters.\n",
        "\n",
        "For example, if we have the following text:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "X-QWgUSy1ARD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocab\n",
        "create a vocab i.e. a dictioanry with word/token as key and int index as value"
      ],
      "metadata": {
        "id": "bglIAngi46vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_corpus = \"<text corpus path .txt>\"\n",
        "with open(text_corpus, 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "tokens = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "tokens = [x.strip() for x in tokens]\n",
        "vocab = {x: i for i, x in enumerate(sorted(list(set(tokens))))}"
      ],
      "metadata": {
        "id": "9otvYR7848kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple tokenizer\n",
        "a tokenizer which takes rach word, without whitesepaces and treats punctuations sperately.\n",
        "\n",
        "needs a vocab of the format {word:int, ...}"
      ],
      "metadata": {
        "id": "RQ-PmXSg1Hqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "MC1BWOMy1VW1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "  def __init__(self, vocab) -> None:\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {v: k for k, v in vocab.items()}\n",
        "\n",
        "  def encode(self, text: str) -> List[int]:\n",
        "    preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "    ids = [self.str_to_int[x.strip()] for x in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, tokens: List[int]) -> str:\n",
        "    text = ' '.join([self.int_to_str[x] for x in tokens])\n",
        "    # replace \\s before the punctuation\n",
        "    text = re.sub(r'([,.?_!\"()\\']|--|\\s)', r'\\1', text)\n",
        "    return text\n",
        ""
      ],
      "metadata": {
        "id": "uxZA2G9C1Frt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ES41WAi446V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}